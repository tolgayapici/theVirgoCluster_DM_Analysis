{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook demonstrates to transform the output of CLUMPY to a template we can use for the HAWC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import astropy.io.fits as fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # may not be necessary\n",
    "import matplotlib.colors as colors\n",
    "import healpy as hp\n",
    "from scipy.interpolate import interp2d\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = [8.0, 6.0]\n",
    "rcParams['xtick.labelsize'] = 14\n",
    "rcParams['ytick.labelsize'] = 14\n",
    "rcParams['axes.labelsize'] = 14\n",
    "rcParams['legend.fontsize'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_cartesian_file(hdus, lon, lat, label, index=1):\n",
    "    content = hdus[index].header\n",
    "    theta_0 = content['THETA_0']\n",
    "    psi_0   = content['PSI_0']\n",
    "    size_x  = content['SIZE_X']\n",
    "    size_y  = content['SIZE_Y']\n",
    "    dangle  = content['ALPHAINT']\n",
    "\n",
    "    content = hdus[index].data\n",
    "    pixels  = content['PIXEL']\n",
    "    Jtotal  = content['Jtot']\n",
    "    Jsmooth = content['Jsmooth']\n",
    "    Jsub    = content['Jsub']\n",
    "    Jcross  = content['Jcrossp']\n",
    "    NSIDE    = hdus[2].header['NSIDE']\n",
    "    ordering = hdus[2].header['ORDERING']\n",
    "    if ordering == \"NESTED\":\n",
    "        nested = True\n",
    "    else:\n",
    "        nested = False\n",
    "\n",
    "    nPix = hp.nside2npix(NSIDE)\n",
    "    num_used_pixels = len(pixels)\n",
    "    theta_rad, phi_rad = hp.pixelfunc.pix2ang(NSIDE, pixels, nest=nested)\n",
    "    # change the angles according to our conventions\n",
    "    theta, phi = -np.degrees(theta_rad-np.pi/2.-lon), np.degrees(np.pi*2.-phi_rad+lat)\n",
    "    phi[np.where(phi>360)] -= 360.\n",
    "    # Process the data for 3ML use\n",
    "    nxPix = 280\n",
    "    nyPix = 280\n",
    "    refX  = 140.5\n",
    "    refY  = 140.5\n",
    "    delX  = -dangle\n",
    "    delY  = dangle\n",
    "    x = np.zeros(nPix)\n",
    "    x[pixels] = Jtotal/np.max(Jtotal)\n",
    "    dmROI = np.zeros([nxPix, nyPix])\n",
    "    for i in range(nxPix):\n",
    "        for j in range(nyPix):\n",
    "            ra_roi = (i-np.int(refX))*delX                                                                          \n",
    "            dec_roi = (j-np.int(refY))*delY\n",
    "            hpix = hp.pixelfunc.ang2pix(NSIDE,np.radians(-dec_roi+90.),np.radians(360.-ra_roi), nest=nested)\n",
    "            #print(hpix)\n",
    "            dmROI[i,j] = x[hpix]\n",
    "    # convert from galactic coordinates to fk5\n",
    "    dmROI = np.multiply(dmROI, (np.degrees(1)**2/delX**2))\n",
    "    coords = SkyCoord(lon*u.degree, lat*u.degree, frame='galactic', unit='degree')\n",
    "    RA  = coords.fk5.ra.degree\n",
    "    DEC = coords.fk5.dec.degree\n",
    "    # write the output to the new file\n",
    "    new_hdu = fits.PrimaryHDU(dmROI)\n",
    "    new_hdu.header['CTYPE1'] = 'RA'\n",
    "    new_hdu.header['CTYPE2'] = 'DEC'\n",
    "    new_hdu.header['CUNIT1'] = 'deg'\n",
    "    new_hdu.header['CUNIT2'] = 'deg'\n",
    "    new_hdu.header['CRPIX1'] = refX\n",
    "    new_hdu.header['CRPIX2'] = refY\n",
    "    new_hdu.header['CRVAL1'] = RA\n",
    "    new_hdu.header['CRVAL2'] = DEC\n",
    "    new_hdu.header['CDELT1'] = delX\n",
    "    new_hdu.header['CDELT2'] = delY\n",
    "    #new_hdu.header['DMAX']   = np.log10(Jtotal.max())\n",
    "    hdulist = fits.HDUList([new_hdu])\n",
    "    hdulist.writeto('{}_Jfactor_template.fits'.format(label))\n",
    "    print(\"For {}: Jmax={}\".format(label, np.log10(Jtotal.max())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header 1: JFACTOR\n",
      "header 2: JFACTOR_PER_SR\n",
      "header 3: INTEGRATED_FLUXES\n",
      "header 1: JFACTOR\n",
      "header 2: JFACTOR_PER_SR\n",
      "header 3: INTEGRATED_FLUXES\n",
      "For M87_gao: Jmax=17.6983528137\n",
      "For M49_gao: Jmax=17.2624816895\n",
      "For VirgoC_gao: Jmax=19.0107460022\n"
     ]
    }
   ],
   "source": [
    "# M87\n",
    "lon_M87 = 283.77\n",
    "lat_M87 = 74.49\n",
    "# M49\n",
    "lon_M49 = 286.92\n",
    "lat_M49 = 70.20\n",
    "# Virgo Cluster\n",
    "lon_Virgo = 283.77\n",
    "lat_Virgo = 74.49\n",
    "\n",
    "M87_coords = SkyCoord(lon_M87*u.degree, lat_M87*u.degree, frame='galactic', unit='degree')\n",
    "M87_lat = M87_coords.galactic.l.radian\n",
    "M87_lon = M87_coords.galactic.b.radian\n",
    "\n",
    "M49_coords = SkyCoord(lon_M49*u.degree, lat_M49*u.degree, frame='galactic', unit='degree')\n",
    "M49_lat = M49_coords.galactic.l.radian\n",
    "M49_lon = M49_coords.galactic.b.radian\n",
    "\n",
    "\"\"\"\n",
    "M87_filename    = \"../output/annihil_M872D_FOVdiameter12.0deg_rse5_alphaint0.11deg_nside1024.fits\"\n",
    "M49_filename    = \"../output/annihil_M492D_FOVdiameter12.0deg_rse5_alphaint0.11deg_nside1024.fits\"\n",
    "VirgoC_filename = \"../output/annihil_VirgoC2D_FOVdiameter12.0deg_rse5_alphaint0.11deg_nside1024.fits\"\n",
    "\"\"\"\n",
    "M87_filename    = \"../output/annihil_M87_GAO2D_FOVdiameter14.0deg_rse1_alphaint0.06deg_nside2048.fits\"\n",
    "M49_filename    = \"../output/annihil_M49_GAO2D_FOVdiameter14.0deg_rse1_alphaint0.06deg_nside2048.fits\"\n",
    "VirgoC_filename = \"../output/annihil_VirgoC_GAO2D_FOVdiameter14.0deg_rse1_alphaint0.06deg_nside2048.fits\"\n",
    "\"\"\"\n",
    "M87_filename    = \"../output/annihil_M87_NFW2D_FOVdiameter14.0deg_rse1_alphaint0.11deg_nside1024.fits\"\n",
    "M49_filename    = \"../output/annihil_M49_NFW2D_FOVdiameter14.0deg_rse1_alphaint0.11deg_nside1024.fits\"\n",
    "VirgoC_filename = \"../output/annihil_VirgoC_NFW2D_FOVdiameter14.0deg_rse1_alphaint0.11deg_nside1024.fits\"\n",
    "\"\"\"\n",
    "M87_hdus = fits.open(M87_filename)\n",
    "M49_hdus = fits.open(M49_filename)\n",
    "Virgo_hdus = fits.open(VirgoC_filename)\n",
    "\n",
    "for i in range(1, len(M87_hdus)):\n",
    "    print(\"header {}: {}\".format(i, M87_hdus[i].header['EXTNAME']))\n",
    "    \n",
    "for i in range(1, len(M49_hdus)):\n",
    "    print(\"header {}: {}\".format(i, M49_hdus[i].header['EXTNAME']))\n",
    "\n",
    "\"\"\"\n",
    "generate_cartesian_file(M87_hdus, lon_M87, lat_M87, \"M87_nfw\")\n",
    "generate_cartesian_file(M49_hdus, lon_M49, lat_M49, \"M49_nfw\")\n",
    "generate_cartesian_file(Virgo_hdus, lon_Virgo, lat_Virgo, \"VirgoC_nfw\")\n",
    "\"\"\"\n",
    "generate_cartesian_file(M87_hdus, lon_M87, lat_M87, \"M87_gao\")\n",
    "generate_cartesian_file(M49_hdus, lon_M49, lat_M49, \"M49_gao\")\n",
    "generate_cartesian_file(Virgo_hdus, lon_Virgo, lat_Virgo, \"VirgoC_gao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data from the fits generated with CLUMPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = hdus[1].header\n",
    "theta_0 = content['THETA_0']\n",
    "psi_0   = content['PSI_0']\n",
    "size_x  = content['SIZE_X']\n",
    "size_y  = content['SIZE_Y']\n",
    "dangle  = content['ALPHAINT']\n",
    "\n",
    "content = hdus[1].data\n",
    "pixels  = content['PIXEL']\n",
    "Jtotal  = content['Jtot']\n",
    "Jsmooth = content['Jsmooth']\n",
    "Jsub    = content['Jsub']\n",
    "Jcross  = content['Jcrossp']\n",
    "NSIDE    = hdus[2].header['NSIDE']\n",
    "ordering = hdus[2].header['ORDERING']\n",
    "if ordering == \"NESTED\":\n",
    "    nested = True\n",
    "else:\n",
    "    nested = False\n",
    "\n",
    "nPix = hp.nside2npix(NSIDE)\n",
    "num_used_pixels = len(pixels)\n",
    "theta_rad, phi_rad = hp.pixelfunc.pix2ang(NSIDE, pixels, nest=nested)\n",
    "# change the angles according to our conventions\n",
    "theta, phi = -np.degrees(theta_rad-np.pi/2.-virgo_lon), np.degrees(np.pi*2.-phi_rad+virgo_lat)\n",
    "phi[np.where(phi>360)] -= 360.\n",
    "\n",
    "print(\"max log10(J)/sr is {}\".format(np.log10(Jtotal.max())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "Jtot = np.ones(nPix)\n",
    "Jtot[pixels] = Jtotal\n",
    "hp.cartview(Jtot, latra=[-7., 7.], lonra=[-7., 7.], nest=nested, \n",
    "            min=1e21, norm='log', title=\"J factor per sr\", unit=\"J/sr\")\n",
    "plt.savefig(\"../original_template.pdf\", bbox_inches='tight')\n",
    "plt.savefig(\"../original_template.png\", bbox_inches='tight')\n",
    "plt.savefig(\"../original_template.eps\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section explains how to transform the CLUMPY generated file to a file that can be used in AERIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(\"interpolator1.pkl\"):\n",
    "    # pickles exist. so only read it and save time\n",
    "    print(\"pickles exist... I will read the interpolators from the pickles...\")\n",
    "    interpolator1 = pickle.load(open(\"interpolator1.pkl\", \"rb\"))\n",
    "    interpolator2 = pickle.load(open(\"interpolator2.pkl\", \"rb\"))\n",
    "else:\n",
    "    print(\"pickles are missing... I will run the analysis for interpolators...\")\n",
    "    interpolator1 = interp2d(theta[:25000], phi[:25000], np.log10(Jtotal[:25000]), bounds_error=True)\n",
    "    interpolator2 = interp2d(theta[25000:], phi[25000:], np.log10(Jtotal[25000:]), bounds_error=True)\n",
    "    with open('interpolator1.pkl', 'wb') as f:\n",
    "        pickle.dump(interpolator1, f)\n",
    "    with open('interpolator2.pkl', 'wb') as f:\n",
    "        pickle.dump(interpolator2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixAngle = hp.pix2ang(NSIDE, range(nPix), nest=nested)\n",
    "lon, lat = -np.degrees(pixAngle[0]-np.pi/2.), np.degrees(np.pi*2.-pixAngle[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pix1 = []\n",
    "j_factors1 = []\n",
    "for i in range(nPix):\n",
    "    try:\n",
    "        j_value  = interpolator1(lon[i], lat[i])[0]\n",
    "        if j_value > 26:\n",
    "            continue\n",
    "        pix1.append(i)\n",
    "        j_factors1.append(j_value)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "pix2 = []\n",
    "j_factors2= []\n",
    "for i in range(nPix):\n",
    "    try:\n",
    "        j_value  = interpolator2(lon[i], lat[i])[0]\n",
    "        if j_value > 26:\n",
    "            continue\n",
    "        pix2.append(i)\n",
    "        j_factors2.append(j_value)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "Jtot = np.zeros(nPix)\n",
    "Jtot[pix1] = j_factors1\n",
    "Jtot[pix2] = j_factors2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Jtot = np.zeros(nPix)\n",
    "Jtot[pix1] = j_factors1\n",
    "for i in range(len(pix2)):\n",
    "    if Jtot[pix2[i]] < 20:\n",
    "        Jtot[pix2[i]] = j_factors2[i]\n",
    "plt.clf()\n",
    "Jtot[np.where(Jtot<=21)] = 0\n",
    "Jtot[np.where(Jtot>=26)] = 0\n",
    "Jtot = 10**Jtot\n",
    "hp.cartview(Jtot, latra=[67., 82.], lonra=[70., 90.], nest=nested, min=1e21, max=1e26,\n",
    "           title=\"J factor per sr\", unit=\"log(J)/sr\", norm='log')\n",
    "plt.savefig(\"../translated_template.pdf\", bbox_inches='tight')\n",
    "plt.savefig(\"../translated_template.png\", bbox_inches='tight')\n",
    "plt.savefig(\"../translated_template.eps\", bbox_inches='tight')\n",
    "plt.show()\n",
    "Jtot = Jtot/np.max(Jtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_hdu = fits.PrimaryHDU(Jtot)\n",
    "new_hdu.header['CTYPE1'] = 'RA'\n",
    "new_hdu.header['CTYPE2'] = 'DEC'\n",
    "new_hdu.header['CUNIT1'] = 'deg'\n",
    "new_hdu.header['CUNIT2'] = 'deg'\n",
    "new_hdu.header['CRPIX1'] = 70.5\n",
    "new_hdu.header['CRPIX2'] = 70.5\n",
    "new_hdu.header['CRVAL1'] = RA\n",
    "new_hdu.header['CRVAL2'] = DEC\n",
    "new_hdu.header['CDELT1'] = -dangle\n",
    "new_hdu.header['CDELT2'] = dangle\n",
    "hdulist = fits.HDUList([new_hdu])\n",
    "hdulist.writeto('VirgoCluster_Jfactor_template.fits')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
